{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Example\n",
    "\n",
    "This example loads 10 mnist images from a subdirectory and classifies them using a W1A2 ConvNet based on QNN-MO-PYNQ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, pickle, random\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "#%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import qnn\n",
    "from qnn import Dorefanet\n",
    "from qnn import utils\n",
    "\n",
    "import sys\n",
    "import scipy.io\n",
    "import json\n",
    "\n",
    "from cs231n.fast_layers import conv_forward_fast, max_pool_forward_fast \n",
    "\n",
    "def exiter():\n",
    "    classifier.deinit_accelerator()\n",
    "    from pynq import Xlnk\n",
    "    xlnk = Xlnk();\n",
    "    xlnk.xlnk_reset() \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Dorefanet()\n",
    "net = classifier.load_network(json_layer=\"/home/xilinx/jupyter_notebooks/QNN/qnn/params/mnist.json\")\n",
    "\n",
    "json_network_custom = \"/home/xilinx/jupyter_notebooks/QNN/qnn/bitstreams/bitmnist.json\"\n",
    "json_layer_custom =   \"/home/xilinx/jupyter_notebooks/QNN/qnn/params/mnist.json\"\n",
    "bit_file_custom =     \"/home/xilinx/jupyter_notebooks/QNN/qnn/bitstreams/mnist.bit\"\n",
    "\n",
    "classifier.init_accelerator(bit_file=bit_file_custom, json_network=json_network_custom, json_layer=json_layer_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the weights for the first conv layer and last FC layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv0_W = np.load('/home/xilinx/jupyter_notebooks/qnnparams/mnist2/binparam-mnist/conv0/W0.npy')\n",
    "conv0_b = np.load('/home/xilinx/jupyter_notebooks/qnnparams/mnist2/binparam-mnist/conv0/b0.npy')\n",
    "conv0_W = np.swapaxes(conv0_W,0,3)\n",
    "conv0_W = np.swapaxes(conv0_W,1,2)\n",
    "conv0_W = np.swapaxes(conv0_W,2,3)\n",
    "\n",
    "activation_bits = 2\n",
    "th = 2**activation_bits-1\n",
    "conv0_T = range(th) \n",
    "conv0_T = np.asarray(conv0_T,dtype=np.float32) \n",
    "conv0_T += 0.5\n",
    "conv0_T /= th;\n",
    " \n",
    "fc0_W = np.load('/home/xilinx/jupyter_notebooks/QNN/qnn/params/binparam-mnist/fc0/W0.npy')\n",
    "fc0_b = np.load('/home/xilinx/jupyter_notebooks/QNN/qnn/params/binparam-mnist/fc0/b0.npy')\n",
    "fc1_W = np.load('/home/xilinx/jupyter_notebooks/QNN/qnn/params/binparam-mnist/fc1/W0.npy')\n",
    "fc1_b = np.load('/home/xilinx/jupyter_notebooks/QNN/qnn/params/binparam-mnist/fc1/b0.npy')\n",
    "\n",
    "out_dim = net['conv3']['output'][1]\n",
    "out_ch =  net['conv3']['output'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now loop over and classify images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1  000015-num5.png    Class 5  , Predicted 5,    Accuracy 100.00\n",
      "#2  000003-num0.png    Class 0  , Predicted 0,    Accuracy 100.00\n",
      "#3  000063-num3.png    Class 3  , Predicted 3,    Accuracy 100.00\n",
      "#4  000081-num6.png    Class 6  , Predicted 6,    Accuracy 100.00\n",
      "#5  000002-num1.png    Class 1  , Predicted 1,    Accuracy 100.00\n",
      "#6  000000-num7.png    Class 7  , Predicted 7,    Accuracy 100.00\n",
      "#7  000061-num8.png    Class 8  , Predicted 8,    Accuracy 100.00\n",
      "#8  000001-num2.png    Class 2  , Predicted 2,    Accuracy 100.00\n",
      "#9  000007-num9.png    Class 9  , Predicted 9,    Accuracy 100.00\n",
      "#10  000004-num4.png    Class 4  , Predicted 4,    Accuracy 100.00\n",
      "Correct: 10 / 10\n",
      "Average Time: 42.3693 ms\n",
      "Fps: 23.601994840603925 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "correct = 0 \n",
    "cur_time = 0;\n",
    "total_time = 0;\n",
    "\n",
    "directory = 'mnist_test/'\n",
    "\n",
    "for root, dirs, files in os.walk(directory):\n",
    "  for name in files: \n",
    "    curr_class = name.split('.')[-2].split('-')[-1][3]\n",
    "    #print(filename)\n",
    "    img_file = os.path.join(root, name)\n",
    "    img = cv2.imread(img_file,0).astype('float32')\n",
    "    img = img / 255.0\n",
    "    \n",
    "    startx = datetime.now()\n",
    "    \n",
    "    img = img [np.newaxis,:,:,np.newaxis]\n",
    "    idx += 1\n",
    "       \n",
    "     \n",
    "    img = np.rollaxis(img,3, 1)\n",
    "    conv_param = {'stride': 1, 'pad': 1}\n",
    "    conv0, _ = conv_forward_fast(img, conv0_W, conv0_b, conv_param)  \n",
    "    \n",
    "     \n",
    "    pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "    conv0, _ = max_pool_forward_fast(conv0, pool_param)    \n",
    "    conv0 = conv0.reshape((64, 14, 14))     \n",
    "       \n",
    "    # The result in then quantized to 2 bits representation for the subsequent HW offload\n",
    "    # conv0 = np.clip(conv0,0,1) # not necessary\n",
    "    conv0 = utils.threshold(conv0, conv0_T)\n",
    "\n",
    "    # Compute offloaded convolutional layers\n",
    "\n",
    "    conv_output = classifier.get_accel_buffer(out_ch, out_dim);\n",
    "    conv_input = classifier.prepare_buffer(conv0)\n",
    "    \n",
    "    classifier.inference(conv_input, conv_output)\n",
    "\n",
    "    conv_output = classifier.postprocess_buffer(conv_output)\n",
    "    fc0_out = utils.fully_connected(conv_output, fc0_W, fc0_b)\n",
    "    fc1_out = utils.fully_connected(fc0_out, fc1_W, fc1_b)\n",
    "\n",
    "    predict = np.argmax(fc1_out)\n",
    "    \n",
    "    endx = datetime.now()\n",
    "    cur_time = (endx - startx).total_seconds()\n",
    "    total_time += cur_time\n",
    "        \n",
    "    if predict == int(curr_class):\n",
    "        correct += 1    \n",
    "                        \n",
    "    print('#{4}  {2}    Class {0}  , Predicted {1},    Accuracy {3:.2f}'.format(curr_class,str(predict),name,correct/idx*100,idx))\n",
    "\n",
    "    if idx == 10:\n",
    "        avg_time = total_time / idx * 1000000\n",
    "        print('Correct: {0} / {1}'.format(correct,idx))\n",
    "        print('Average Time: {0} ms'.format(avg_time/1000))\n",
    "        print('Fps: {0} \\n\\n'.format(1/avg_time*1e6)) \n",
    "        \n",
    "        exiter()\n",
    "       \n",
    "exiter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
